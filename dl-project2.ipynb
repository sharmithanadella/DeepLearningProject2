{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:05:58.800477Z","iopub.execute_input":"2025-04-07T18:05:58.800740Z","iopub.status.idle":"2025-04-07T18:06:01.002093Z","shell.execute_reply.started":"2025-04-07T18:05:58.800719Z","shell.execute_reply":"2025-04-07T18:06:01.001347Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# -----------------------------\n# 1. Import libraries\n# -----------------------------\nimport torch\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer\nfrom datasets import load_dataset\nfrom peft import get_peft_model, LoraConfig, TaskType\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\nimport pandas as pd\nimport pickle\n\n# -----------------------------\n# 2. Use GPU if available\n# -----------------------------\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# -----------------------------\n# 3. Load and preprocess AGNEWS dataset\n# -----------------------------\ndataset = load_dataset(\"ag_news\")\ntokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n\ndef tokenize_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n\ntokenized_dataset = dataset.map(tokenize_function, batched=True)\ntokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\ntokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"labels\"])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:12:20.883662Z","iopub.execute_input":"2025-04-07T18:12:20.883971Z","iopub.status.idle":"2025-04-07T18:13:07.029719Z","shell.execute_reply.started":"2025-04-07T18:12:20.883949Z","shell.execute_reply":"2025-04-07T18:13:07.028830Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/8.07k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"566bcf75729243669323c66afe798467"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train-00000-of-00001.parquet:   0%|          | 0.00/18.6M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"95d85feb86af4733ab59e1fe7fe23822"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"test-00000-of-00001.parquet:   0%|          | 0.00/1.23M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b486a1415d314913a80cd89708966c16"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8b2e92032b0497e90d07912bd11af12"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6205c23d4da4a2a8ea86dcf304867dc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b53e7b2c97254b1e906795c94f1f70a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"19b8e36d79f648afa3a5fe580f464765"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0fca6aa6d1914787b328f4162f1e8e5c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e05df64d8b2449f5800aa0bb595babd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"577dacf6475749a18d8f1f0e55531dc5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9ad6ac9ff57a49658e122a362ba83297"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7600 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d5945a5db8847fabe554b7da3651a20"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"# -----------------------------\n# 4. Load RoBERTa model with LoRA adapters\n# -----------------------------\nmodel = AutoModelForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=4)\n\nlora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    target_modules=[\"query\", \"value\"],\n    lora_dropout=0.1,\n    bias=\"none\",\n    task_type=TaskType.SEQ_CLS\n)\n\nmodel = get_peft_model(model, lora_config)\nmodel.to(device)\nmodel.print_trainable_parameters()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:13:07.030826Z","iopub.execute_input":"2025-04-07T18:13:07.031099Z","iopub.status.idle":"2025-04-07T18:13:09.950073Z","shell.execute_reply.started":"2025-04-07T18:13:07.031072Z","shell.execute_reply":"2025-04-07T18:13:09.949273Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"16dd21a1482b41b7a449487dbeab323e"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"name":"stdout","text":"trainable params: 888,580 || all params: 125,537,288 || trainable%: 0.7078\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# -----------------------------\n# 5. Define training arguments\n# -----------------------------\ntraining_args = TrainingArguments(\n    output_dir=\"./results\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"no\",\n    learning_rate=2e-4,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=64,\n    num_train_epochs=3,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    report_to=\"none\"\n)\n\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    predictions = np.argmax(logits, axis=-1)\n    return {\"accuracy\": accuracy_score(labels, predictions)}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:13:09.951363Z","iopub.execute_input":"2025-04-07T18:13:09.951687Z","iopub.status.idle":"2025-04-07T18:13:09.989078Z","shell.execute_reply.started":"2025-04-07T18:13:09.951661Z","shell.execute_reply":"2025-04-07T18:13:09.988091Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# -----------------------------\n# 6. Train the model\n# -----------------------------\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset[\"train\"],\n    eval_dataset=tokenized_dataset[\"test\"],\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T18:13:44.520678Z","iopub.execute_input":"2025-04-07T18:13:44.520996Z","iopub.status.idle":"2025-04-07T19:21:05.440262Z","shell.execute_reply.started":"2025-04-07T18:13:44.520971Z","shell.execute_reply":"2025-04-07T19:21:05.439520Z"}},"outputs":[{"name":"stderr","text":"<ipython-input-7-5eac8a011c90>:4: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n  trainer = Trainer(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='11250' max='11250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [11250/11250 1:07:20, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.202200</td>\n      <td>0.195394</td>\n      <td>0.936184</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.185700</td>\n      <td>0.179817</td>\n      <td>0.940000</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.165100</td>\n      <td>0.175662</td>\n      <td>0.942237</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=11250, training_loss=0.19213385789659287, metrics={'train_runtime': 4040.458, 'train_samples_per_second': 89.099, 'train_steps_per_second': 2.784, 'total_flos': 2.392609480704e+16, 'train_loss': 0.19213385789659287, 'epoch': 3.0})"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# -----------------------------\n# 7. Evaluate the model\n# -----------------------------\neval_results = trainer.evaluate()\nprint(\"Final Evaluation Accuracy:\", eval_results[\"eval_accuracy\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T19:21:05.441422Z","iopub.execute_input":"2025-04-07T19:21:05.441738Z","iopub.status.idle":"2025-04-07T19:21:35.830254Z","shell.execute_reply.started":"2025-04-07T19:21:05.441703Z","shell.execute_reply":"2025-04-07T19:21:35.829383Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/nn/parallel/_functions.py:71: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [60/60 00:29]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"Final Evaluation Accuracy: 0.9422368421052632\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# -----------------------------\n# 8. Check trainable parameter count\n# -----------------------------\ntrainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Trainable parameters: {trainable_params}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T19:21:35.831893Z","iopub.execute_input":"2025-04-07T19:21:35.832133Z","iopub.status.idle":"2025-04-07T19:21:35.837958Z","shell.execute_reply.started":"2025-04-07T19:21:35.832112Z","shell.execute_reply":"2025-04-07T19:21:35.837019Z"}},"outputs":[{"name":"stdout","text":"Trainable parameters: 888580\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"from datasets import Dataset\nfrom torch.utils.data import DataLoader\n\n# Load dataset object\nwith open(\"/kaggle/input/deep-learning-spring-2025-project-2/test_unlabelled.pkl\", \"rb\") as f:\n    test_dataset = pickle.load(f)\n\n# Convert to HuggingFace Dataset (already is, but this helps formatting)\ntest_dataset = Dataset.from_dict({\"text\": test_dataset[\"text\"]})\n\n# Tokenize function\ndef preprocess_function(examples):\n    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n\n# Apply tokenizer\ntokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\ntokenized_test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\"])\n\n# Create PyTorch DataLoader for batching\ntest_dataloader = DataLoader(tokenized_test_dataset, batch_size=64)\n\n# Prediction loop\nmodel.eval()\nall_predictions = []\n\nwith torch.no_grad():\n    for batch in test_dataloader:\n        batch = {k: v.to(device) for k, v in batch.items()}\n        outputs = model(**batch)\n        preds = torch.argmax(outputs.logits, dim=-1)\n        all_predictions.extend(preds.cpu().numpy())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T19:25:24.599476Z","iopub.execute_input":"2025-04-07T19:25:24.599796Z","iopub.status.idle":"2025-04-07T19:26:25.397229Z","shell.execute_reply.started":"2025-04-07T19:25:24.599774Z","shell.execute_reply":"2025-04-07T19:26:25.396488Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/8000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f95a05e0b5ca4cc68d396b79dce248ed"}},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"# -----------------------------\n# 10. Save predictions to CSV\n# -----------------------------\ndf = pd.DataFrame({\n    \"ID\": list(range(len(all_predictions))),   # ID âœ…\n    \"label\": all_predictions\n})\ndf.to_csv(\"submission.csv\", index=False)\nprint(\"âœ… Batched predictions complete. Saved to submission.csv.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-07T19:35:04.652958Z","iopub.execute_input":"2025-04-07T19:35:04.653420Z","iopub.status.idle":"2025-04-07T19:35:04.686138Z","shell.execute_reply.started":"2025-04-07T19:35:04.653386Z","shell.execute_reply":"2025-04-07T19:35:04.685245Z"}},"outputs":[{"name":"stdout","text":"âœ… Batched predictions complete. Saved to submission.csv.\n","output_type":"stream"}],"execution_count":18}]}